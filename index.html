<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">

  <title>DataLad</title>

  <meta name="description" content="DataLad Talk given at ABCD Resting State Call, Internets, 2022">
  <meta name="author" content="Yaroslav Halchenko">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
  <link rel="stylesheet" href="s.css" id="theme">
  <!-- Code syntax highlighting -->
  <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
  <!-- Printing and PDF exports -- disabled for now
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
 -->
  <link rel="stylesheet" href="s.css" id="theme">
  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
<!--<style type="text/css">
    dt, dd { display: inline-block; float: left; }
    dt { clear: left; }
</style>
-->
</head>
<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<section>
  <h1 style="text-transform:none">DataLad</h1>
  <p style="margin-top:-10px"><a href="http://datalad.org">http://datalad.org</a></p>
  <p style="margin-top:-10px"><a href="http://datalad.org">https://github.com/datalad/talk-2022-abcd</a></p>
  <div style="margin-top:1em;text-align:center">
  <table style="border: none;">
  <tr>
	<td>Yaroslav O. Halchenko
	  <br><small>
		<a href="https://twitter.com/yarikoptic">
		  <img data-src="pics/twitter.png" style="height:30px;margin:0px" />
		  @yarikoptic</a></small></td>
	<td>DataLad Developers
	  <br><small>
		<a href="https://twitter.com/datalad">
		  <img data-src="pics/twitter.png" style="height:30px;margin:0px" />
		  @datalad</a></small></td>
  </tr>
  <tr>
    <td>
      <small>
		<a href="http://centerforopenneuroscience.org">Center for Open Neuroscience</a>, <br />
 		<a href="https://pbs.dartmouth.edu">Dept. Psychological and Brain Sciences</a>, <br />
 		  <a href="https://dartmouth.edu">Dartmouth College</a>
      </small>
    </td>
    <td>
		<a href="https://datalad.org">Planet Earth</a> <br />
    </td>
  </tr>
  </table>
  </div>
  
  <div style="margin-top:1em">
  <img style="height:150px;margin-right:50px" data-src="pics/nsf.png" />
  <img style="height:150px;margin-left:50px" data-src="pics/bmbf.png" />
  <img style="height:150px;margin-right:50pxi;margin-left:50px" data-src="pics/binc.png" />
  <br />
  <!-- TODO: add ReproNim  # to the NIH logo -->
  <img style="height:80px;margin-right:20px" data-src="pics/nih.png" />
  <img style="height:80px;margin:20px" data-src="pics/erdf.png" />
  <img style="height:80px;margin:20px" data-src="pics/LSA-Logo.png" />
  </div>
</section>


<section data-transition="fade">
<section>
  <h2>(Original) motivation for DataLad</h2>
  <ul style="font-size:120%">
	<li style="margin-top:1em">A growing amount of neural data is getting shared</li>
	<ul style="font-size:90%">
	  <li>cacophony of authentication schemes, interfaces,
		protocols</li>
      <li>difficulty to share new or derived data</li>
	</ul>
	<li style="margin-top:1em">Software distributions are inadequate for data
	  <ul style="font-size:90%">
		<li>modularity is less well defined <br>
		  (interest could be in specific group of files, videos-vs-images or humans-vs-objects, etc)</li>
		<li>data is less volatile (lesser versions, only a few files change)</li>
		<li>tarballs are inefficient</li>
		<li>we cannot host copies of all data</li>
	  </ul>
	</li>
  </ul>
</section>

<!-- cheat sheet
<section>
	<p class="fragment grow">grow</p>
	<p class="fragment shrink">shrink</p>
	<p class="fragment fade-out">fade-out</p>
	<p class="fragment fade-up">fade-up (also down, left and right!)</p>
	<p class="fragment fade-in-then-out">fades in, then out when we move to the next step</p>
	<p class="fragment fade-in-then-semi-out">fades in, then obfuscate when we move to the next step</p>
	<p class="fragment highlight-current-blue">blue only once</p>
	<p class="fragment highlight-red">highlight-red</p>
	<p class="fragment highlight-green">highlight-green</p>
	<p class="fragment highlight-blue">highlight-blue</p>
</section>
-->

<section>
  <h2>(Further) motivation for DataLad is Git</h2>
  <ul style="font-size:120%">
	<p>
	<li style="margin-top:1em">Git is a blessing for
	  <ul style="font-size:90%">
		<li>collaboration</li>
		<li>experimentation</li>
		<li>automation</li>
		<li>provenance tracking</li>
	  </ul>
	<li style="margin-top:1em">We (and many others got to) love Git</li>
  </ul>
</section>

<section>
  <h2>What is Git?</h2>
</section>

<section data-transition="fade-in">
  <h2>Git is ...</h2>

<p class="fragment fade-in-then-out">a Version Control System!</p>
<pre class="fragment fade-in-then-out"><code class="bash" style="max-height:none">$ man git

GIT(1)                            Git Manual                            GIT(1)

NAME
       git - the stupid content tracker

SYNOPSIS
       ...

DESCRIPTION
       Git is a fast, scalable, distributed revision control system with an
       unusually rich command set that provides both high-level operations and
       full access to internals.
</code></pre>
  <p class="fragment fade-in" style="font-size:120%">a Distributed Revision Control System
	<br/>AKA "the stupid content tracker"</p>

</section>

<section>
  <h2>Git ...</h2>
  <ul style="font-size:120%">
	<li>tracks content (files, file trees, commits)</li>
	<li>stores all known content in object store (<emph class="path">.git/objects</emph>)</li>
	<li>efficiently exchanges objects and references
	  <br/>(branches, tags) with remote instances</li>
	<li style="margin-top:1em">is <strong>great</strong> for code</li>
	<li>is inadequate for data</li>
	  <ul style="font-size:90%">
		<li><strong>all objects</strong> are distributed across all
		copies</li>
		<li>duplicate content between work tree and object store</li>
	  </ul>
  </ul>
</section>

</section>



<section data-transition="fade">
<section>
  <h1>
  <img style="" height="200px" data-src="pics/datalad-animated.gif">
  </h1>
  <!--
  <p style="margin-top:100px">A data management suite that makes <strong>YOU</strong> more productive,</p>
  <p style="margin-top:100px">...and <em>also</em> yields FAIR
  resources<br />that you can share with anyone you see fit.</p>
-->
  <p style="margin-top:200px;font-size:150%">
	A data management suite that makes data
	access and management as easy as managing code and software!</p>

</section>
</section>


<section data-transition="fade">
  <section>
    <h2>Datalad principles</h2>
    <ul style="font-size:120%">
        <li style="margin-bottom:1em">There are only two things in the world: <strong>datasets and files</strong></li>
        <li style="margin-bottom:1em">A <strong>dataset is a Git repository</strong></li>
        <li style="margin-bottom:1em">A dataset can have an <strong>optional <em>annex</em></strong> for (large) file content tracking (transport to and from the annex managed with Git-annex, <a href="https://git-annex.branchable.com">https://git-annex.branchable.com</a>)</li>
        <li style="margin-bottom:1em">Minimization of custom
        procedures and data structures: <br><strong>Users must not
			loose data or data access</strong>,
		  <br> if DataLad would vanish</li>
        <li style="margin-bottom:1em"><strong>Complete decentralization</strong>, no required central server or service</li>
        <li style="margin-bottom:1em"><strong>Maximization of existing
        3rd-party data resources and infrastructure re-use</strong></li>
    </ul>

  </section>

  <section data-transition="slide">
	<h2>DataLad in one figure</h2>
	<img style="" data-src="pics/datalad_process_tuned/00base_preview.png">
  </section>

  <!--
  <section>
	<h2>Dataset: tracking content and/or its identifiers</h2>
	<img style="" data-src="pics/dataset_concept.png">
	<dl>
      <dt>Dataset ID, Dataset annex (local) storage ID</dt><dd>two distinct UUIDs</dd>
      <dt>Dataset version (Git repository state)</dt><dd>SHASUM (+
      git tags, "git describe")</dd>
	  <dt>File</dt><dd>git-annex key - configurable checksum (file content based)</dd>
	</dl>
  </section>
  -->
</section>

<section>
  <section>
	<h2>Install</h2>
	<img style="" data-src="pics/datalad_process_tuned/install_preview.png">
  </section>

  <section data-transition="fade">
    <h2>Install an existing dataset</h2>
    <img data-src="pics/dl_download_ds02.png">
    <p style="margin-top:-4em">request via standard URL or SSH address</p>
    <pre class="codefootnote"><code class="bash">$ datalad install smaug.datalad.org:/mnt/datasets/datalad/crawl-misc/abcd/abcd-bids</code></pre>

	<ul>
    <li><emph>install</emph> (if used without -g and -r) is <strong>fast</strong></li>
	<li>Dataset file and sub-datasets hierarchy is available right away for exploration</li>
	<li>Some (small) metadata and documentation files can be made available directly from Git</li>
	<li>... or could all be contained in git-annex if e.g. containing sensitive data.</li>
	</ul>
  </section>

  
  <section data-transition="fade">
    <h2>Obtain content</h2>
    <img data-src="pics/dl_download_ds05.png">
    <p style="margin-top:-2em">by requesting via a user-friendly local file path,
	  <br/>not an internal ID or some remote URL,<br />regardless of remote actual storage solution properties</p>
    <pre class="codefootnote"><code class="bash">abcd-bids/ $ datalad get task-nback_bold.json</code></pre>
    <p class="notes">obtain individual files or groups thereof or all of them, <br/> or subdatasets, such as, e.g., per-subject dataset:</p>
    <pre class="codefootnote"><code class="bash">abcd-bids/ $ datalad get sub-NDARINVSENSORED/</code></pre>

  </section>

  <section data-transition="fade">
    <h2>Drop content</h2>
    <!-- TODO <img data-src="pics/dl_download_ds05.png"> -->
    <p style="margin-top:2em" style="font-size:120%">which is no longer needed</p>
    <pre class="codefootnote"><code class="bash">abcd-bids/ $ datalad drop sub-NDARINVSENSORED/</code></pre>
    <p style="margin-top:2em" style="font-size:120%">but rest assured that you would not loose a file, <br/>content for which is not available from elsewhere</p>
	<pre><code class="bash">mynewproj/ $ datalad drop a-new-unique-file
drop(error): /tmp/myproj/a-new-unique-file (file) [unsafe; Could only verify
the existence of 0 out of 1 necessary copies; Rather than dropping this file,
try using: git annex move; (Use --force to override this check, or adjust
numcopies.)]</code></pre>
  </section>

  <section data-transition="fade">
    <h2>Track "remote" data evolution</h2>
    <img data-src="pics/dl_download_ds08.png">
    <p style="margin-top:-2em">from any number of dataset "siblings",
	  <br /> in Git (git remotes) or non-Git (git-annex special remotes)
	  <br /> data stores
	</p>
    <pre class="codefootnote"><code class="bash">abcd-bids/ $ datalad update</code></pre>
	<ul>
	  <li>update data availability information</li>
	</ul>
  </section>

  <section data-transition="fade">
    <h2>Keep up-to-date</h2>
    <img data-src="pics/dl_download_ds11.png">
    <p style="margin-top:-2em">by applying changes from default or selected sibling<br />while maintaining local data availability status</p>
    <pre class="codefootnote"><code class="bash">abcd-bids/ $ datalad update --how=merge --reobtain-data -r</code></pre>
	<ul>
	  <li>update the state to the most recent version</li>
	  <li>update data to new versions</li>
	  <li>do it across entire hierarchy of (sub)datasets</li>

	</ul>
  </section>
</section>

<!-- Creating an populating -->

<section>
  <section>
	<h2>Create</h2>
	<img style="" data-src="pics/datalad_process_tuned/create_preview.png">
  </section>

  <section data-transition="fade">
    <h2>Create a new dataset from scratch</h2>
    <p style="margin-top:4em">One simple command</p>
    <pre class="codefootnote"><code class="bash">$ datalad create myproj</code></pre>
    <p style="margin-top:-0em">instead of</p>
	<pre class="codefootnote"><code class="bash">$ mkdir myproj && cd myproj && git init && git annex init</code></pre>
	<p>with available options such as</p>
	<ul>
	  <li><emph>-c text2git</emph> to instruct annex to commit text files (code)
		<br/> directly to git</li>
	  <li><emph>--no-annex</emph> to not initiate git-annex and keep it pure git</li>
	  <li><emph>--fake-dates</emph> to avoid using true date in commit timestamps (sensitive data?)</li>
	</ul>
  </section>

  <section data-transition="fade">
    <h2>Populate with your content</h2>
    <p style="margin-top:0em"><strong>Any</strong>, regardless how large, file can be added to dataset</p>
	<pre><code class="bash" style="max-height:none">myproj/ $ cp ~/data-I-do-not-want-to-loose/big.dat .

myproj/ $ datalad add -m "Added my favorite big file" big.dat
add(ok): myproj/big.dat (file)
save(ok): myproj (dataset)
action summary:
  add (ok: 1)
  save (ok: 1)

myproj/ $ git show
commit f12facca4f0dde30c69702ac84edc8deebb5a467 (HEAD -> master)
Author: Yaroslav Halchenko &lt;debian@onerussian.com&gt;
Date:   Fri Mar 22 13:51:37 2019 -0400

    Added my favorite big file

diff --git a/big.dat b/big.dat
new file mode 120000
index 0000000..54d7bcd
--- /dev/null
+++ b/big.dat
@@ -0,0 +1 @@
+.git/annex/objects/P0/vx/MD5E-s18681--b1d886e662133db668c4bf2ed1b6dfab.dat/MD5E-s18681--b1d886e662133db668c4bf2ed1b6dfab.dat
	</code></pre>
  </section>

  <section>
	<h2>Crawl</h2>
	<img style="" data-src="pics/datalad_process_tuned/crawl_preview.png">
  </section>

    <section data-transition="fade">
      <h2>Populate with content from the web</h2>
    <p style="margin-top:2em" style="font-size:120%"><emph class="command">git-annex addurl</emph> makes it easy to add any file pointed by a URL</p>
	<pre><code class="bash" style="max-height:none">myfirstcifar/ $ git annex addurl --pathdepth=-1 \
		https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
addurl https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz 
(to cifar_10_python.tar.gz) ok
(recording state in git...)

myfirstcifar/ $ ls -lL cifar_10_python.tar.gz
-r-------- 1 yoh yoh 170498071 Mar 22 14:02 cifar_10_python.tar.gz</code></pre>

	  <p style="font-size:120%">and keeps track of where from
		<br />(which repository, data store, or a URL)
		<br />each file's content is available from</p>
	  <pre><code class="bash" style="max-height:none">myfirstcifar/ $ git annex whereis cifar_10_python.tar.gz 
whereis cifar_10_python.tar.gz (2 copies) 
  	00000000-0000-0000-0000-000000000001 -- web
   	46fe3ab9-139f-465a-a257-7b22e56d2fb8 -- yoh@hopa:/tmp/myfirstcifar [here]

  web: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
ok	  </code></pre>
  </section>


  <section data-transition="fade">
    <h2>Crawl the web for content</h2>
    <!-- TODO <img data-src="pics/dl_download_ds02.png"> -->
    <p style="margin-top:0em"><a href="https://github.com/datalad/datalad-crawler">datalad-crawler</a> extension makes it possible to scrape
	  <br />websites, AWS S3, custom portals etc. to populate datasets with content</p>
	<pre><code class="bash" style="max-height:none">cifar/ $ datalad crawl-init --save --template=simple_with_archives \
		'url=https://www.cs.toronto.edu/~kriz/cifar.html'  \
		'a_href_match_=.*cs.toronto.edu/.*cifar-.*'        \
		'archives_re=\.gz$'                                \
		'leading_dirs_depth=0'

cifar/ $ datalad crawl
[INFO   ] Total stats: URLs processed: 6, downloaded: 6, size: 1.0 GB,
          Files processed: 48, +annex: 42,
		  Branches merged: incoming->incoming-processed,  Datasets crawled: 1</code></pre>
	<p>so that data becomes readily available for use
	  <br/>(e.g., extracted from archives)</p>
	<pre><code class="bash" style="max-height:none">cifar/ $ ls
cifar-10-batches-bin/  cifar-10-batches-mat/  cifar-10-batches-py/
cifar-100-binary/      cifar-100-matlab/      cifar-100-python/

cifar/ $ /bin/ls cifar-10-batches-py
batches.meta  data_batch_1  data_batch_2  data_batch_3 ...
</pre></code>
	<ul>
	  <li>this git repository can be shared as any other git repository</li>
	  <li><strong>Note: unless sensitive data in filenames/git</strong></li>
	  <li>data will be available from original location</li>
	  <li>subsequent <emph>datalad crawl</emph> would update dataset web content changes</li>
	</ul>
  </section>

    <section data-transition="fade">
    <h2>Use datalad addurls and/or write your own scripts to populate</h2>

	<img style="" data-src="pics/datalad-nda-20220313.png"/>
	</section>

	<section>
	  <h2>One way or another - you will not be alone...</h2>
	  <img style=""  data-src="pics/datalad-usage-dashboard-20220313.png">

	  <p>Auto-discovered DataLad datasets on GitHub and OSF:<br>
		<a href="https://github.com/datalad/datalad-usage-dashboard">
		  <img data-src="pics/github-octocat-256.png" style="height:30px;margin:0px" />
		  datalad/datalad-usage-dashboard</a>
	  </p>
	</section>

	<section data-transition="None">
	  <h2>... and take advantage of many services...</h2>
    <ul>
        <li>DataLad is built to maximize interoperability and use with hosting and
            storage technology</li>
    </ul>
    <img class="fragment" src="pics/services_only.png" height="650">
	</section>

	<section data-transition="None">
      <h2>... to solve YOUR data logistics puzzle!</h2>
      <ul>
        <li>DataLad is built to maximize interoperability and use with hosting and
          storage technology</li>
      </ul>
      <img src="pics/services_connected.png" height="650">
	</section>


</section>

<section>
  <section>
	<h2>Dataset linkage</h2>
	<img style="" data-src="pics/datalad_process_tuned/nesting_preview.png">
  </section>

  <section>
	<h2>Dataset linkage</h2>
	<img data-src="pics/dataset_linkage.png">
	<pre><code class="diff" style="max-height:none">$ datalad install --dataset . --source ///cifar data/rawdata

$ git diff HEAD~1
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..c3370ba
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,3 @@
+[submodule "data/rawdata"]
+       path = data/rawdata
+       url = http://datasets.datalad.org/cifar/.git
diff --git a/data/rawdata b/data/rawdata
new file mode 160000
index 0000000..fabf852
--- /dev/null
+++ b/inputs/rawdata
@@ -0,0 +1 @@
+Subproject commit 0000f59a5e68cf035931e78ed61b6327fbc3bdba
	</code></pre>
  </section>

    <section data-transition="None">
    <h2>Datasets all the way down:</h2>

    <ul>
        <li>Link datasets as "dependencies":
                <img height="330"  src="pics/linkage_subds.svg">
            <ul>
                <li>hierarchies of datasets in super-/sub-dataset relationships</li>
                </ul>
        <li class="fragment" data-fragment-index="2">Benefit: Scalability (as for ABCD) </li>
        <pre  class="fragment" data-fragment-index="2">
		  <code>adina@bulk1 in /ds/hcp/super on git:master❱ datalad status --annex -r
15530572 annex'd files (77.9 TB recorded total size)
nothing to save, working tree clean</code></pre>
        <small><a class="fragment fade-in" data-fragment-index="2" href="https://github.com/datalad-datasets/human-connectome-project-openaccess" target="_blank">(github.com/datalad-datasets/human-connectome-project-openaccess)</a></small>
        <li class="fragment">Benefit: Modularizes research components for transparency, reuse, and access management</li>
    </ul>

    <aside class="notes">
        Two advantages:
        <ul>
            <li>Scalable, size-independent version control</li>
            <li>Modularization of research components to increase transparency
                and aid component reuse, as individual components can be flexibly
            puzzled together into new research objects, while being uniquely identified and versioned</li>
        </ul>

        At this point: Fixed data management, layed a foundation for updating data
    </aside>
</section>

<section>
  <h2>An example in "files":</h2>
  <img style="" height="800px" data-src="pics/virtual_dirtree.png">

  <p>For management of computing containers with DataLad, see <a href="https://github.com/datalad/datalad-container/">datalad-container</a> extension, and <a href="https://github.com/ReproNim/containers/">ReproNim/containers</a> DataLad dataset.</p>
</section>

<section>
  <h2>Meet the "largest" Git "repository"</h2>
  <img style=""  data-src="pics/datasets.datalad.org-20220313.png">

  <p>over 6,000 Git repositories as "subdatasets", <br>
	with access to almost 500TB of neural data</p>
</section>

  <section>
	<h2>... which could be beaten by BIDS ABCD</h2>
	<pre><code class="diff" style="max-height:none">abcd-bids $ datalad subdatasets | sed -e 's,INV[^ ]*,SENSORED,g' | nl | tail
 10031	subdataset(ok): sub-NDARSENSORED (dataset)
 10032	subdataset(ok): sub-NDARSENSORED (dataset)
 10033	subdataset(ok): sub-NDARSENSORED (dataset)
 10034	subdataset(ok): sub-NDARSENSORED (dataset)
 10035	subdataset(ok): sub-NDARSENSORED (dataset)
 10036	subdataset(ok): sub-NDARSENSORED (dataset)
 10037	subdataset(ok): sub-NDARSENSORED (dataset)
 10038	subdataset(ok): sub-NDARSENSORED (dataset)
 10039	subdataset(ok): sub-NDARSENSORED (dataset)
 10040	subdataset(ok): sub-NDARSENSORED (dataset)
	</code></pre>
  </section>


</section>

<section data-transition="slide">
  <section>
	<h2>Data provenance capture</h2>
	<img style="" data-src="pics/datalad_process_tuned/run_preview.png">
  </section>

<section data-transition="None">
    <h2>Provenance capture</h2>
    <ul>
        <li>Datasets can capture dataset <b>transformations</b> and their <b>cause</b> in order
            to track the entire evolution and lineage of files in datasets</li>
            </ul>
        <img src="pics/w3cprov.png" width="700">
        <ul>
        <li>"How did this file came to be?",
            "What steps were undertaken to transform the raw data into the published result?",
            "Can you recompute this for me?"
        </li>
            </ul>

</section>

<section data-transition="None">
    <h2>Provenance capture</h2>
    <ul>
        <li><b>Basic provenance</b>: DataLad can capture arbitrary dataset
            transformations (e.g., from computing analysis results) and record
            the cause of such a change
        </li>
            <pre><code class="bash" style="max-height:none">$ datalad run -m "Perform eye movement event detection"\
  --input 'raw_data/*.tsv.gz' --output 'sub-*' \
  bash code/compute_all.sh

-- Git commit -- Michael Hanke < ... @gmail.com>; Fri Sep 21 22:00:47 2019
    [DATALAD RUNCMD] Perform eye movement event detection
    === Do not change lines below ===
    {
     "cmd": "bash code/compute_all.sh",
     "dsid": "d2b4b72a-7c13-11e7-9f1f-a0369f7c647e",
     "exit": 0,
     "inputs": ["raw_data/*.tsv.gz"],
     "outputs": ["sub-*"],
     "pwd": "."
    }
    ^^^ Do not change lines above ^^^
---
 sub-01/sub-01_task-movie_run-1_events.png | 2 +-
 sub-01/sub-01_task-movie_run-1_events.tsv | 2 +-
...</code></pre>
    </ul>
</section>

<section data-transition="None">
    <h2>Provenance capture</h2>
    <ul>
        <li><b>Computational provenance</b>: Datasets can track <b>software containers</b> (see <a href="https://github.com/datalad/datalad-container/">datalad-container</a>),
            and perform and record computations inside it:
        </li>
            <pre><code class="bash" style="max-height:none">$ datalad containers-run -n neuroimaging-container \
  --input 'mri/*_bold.nii --output 'sub-*/LC_timeseries_run-*.csv' \
  "bash -c 'for sub in sub-*; do for run in run-1 ... run-8;
     do python3 code/extract_lc_timeseries.py \$sub \$run; done; done'"

-- Git commit -- Michael Hanke < ... @gmail.com>; Fri Jul 6 11:02:28 2019
    [DATALAD RUNCMD] singularity exec --bind {pwd} .datalad/e...
    === Do not change lines below ===
    {
     "cmd": "singularity exec --bind {pwd} .datalad/environments/nilearn.simg bash..",
     "dsid": "92ea1faa-632a-11e8-af29-a0369f7c647e",
     "inputs": [
      "mri/*.bold.nii.gz",
      ".datalad/environments/nilearn.simg"
     ],
     "outputs": ["sub-*/LC_timeseries_run-*.csv"],
     ...
    }
    ^^^ Do not change lines above ^^^
---
 sub-01/LC_timeseries_run-1.csv | 1 +
...</code></pre>
    </ul>
</section>

<section data-transition="None">
    <h2>Provenance capture</h2>
    <ul>
         <li>All recorded transformations can be re-computed automatically</li>
            <pre><code class="bash" style="max-height:none">$ datalad rerun eee1356bb7e8f921174e404c6df6aadcc1f158f0
[INFO] == Command start (output follows) =====
[INFO] == Command exit (modification check follows) =====
add(ok): sub-01/LC_timeseries_run-1.csv (file)
...
save(ok): . (dataset)
action summary:
  add (ok: 45)
  save (notneeded: 45, ok: 1)
  unlock (notneeded: 45)
...</code></pre>

    <ul>
        <li>Aid with the reproducibility of a result and verify it (via content hash)</li>
        <li>Use complete capture and automatic re-computation as alternative to storage and transport</li>
</li></li>
    </ul>

    </ul>
</section>

</section>

<section>
  <section>
	<h2>Push (formerly: Publish)</h2>
	<img style="" data-src="pics/datalad_process_tuned/publish_preview.png">
  </section>

  <section>
    <h2>Push (formerly: Publish)</h2>

    <ul>
      <li>Wide variety of supported storage solutions (SSH-servers, GIN, DropBox, Box.com, Google,
        WEBDAV, bittorrent, IPFS, ...) via Git-annex</li>
	  <li><a href="http://datasets.datalad.org">datasets.datalad.org</a>
		is just a sample of a "datalad publish"-ed dataset</li>
	  <li>Full support for data encryption</li>
      <li>Multiple redundant synchronized publication targets are supported ("publish 2TB on GitHub")</li>
      <li>Per-target configuration of accepted content, with dedicated set of permissions and authorization mechanisms</li>
	  <li>Export of dataset to FigShare and similar storage solutions</li>
	  <li>Setup <a href="https://handbook.datalad.org/en/latest/r.html?RIA">"RIA stores"</a> for scalable central data management, archival, or backup</li>
	  <li><a href="https://github.com/datalad/datalad-osf/">datalad-osf</a> extension allows to publish data on OSF
    </ul>
  </section>

  <section>
	<h2>Publish to GitHub (to share code)</h2>
	<p>We all know how to do it!
	  <br/>But with DataLad no need to leave terminal</p>
	<pre><code class="bash" style="max-height:none">cifar/ $ datalad create-sibling-github --github-login yarikoptic demo-cifar-preproc
.: github(-) [https://yarikoptic@github.com/yarikoptic/demo-cifar-preproc.git (git)]
'https://yarikoptic@github.com/yarikoptic/demo-cifar-preproc.git' configured as sibling
'github' for &lt;Dataset path=.../cifar&gt;</code></pre>

<pre><code class="bash" style="max-height:none">cifar/ $ datalad push --to=github
[INFO   ] Publishing &lt;Dataset path=.../cifar&gt; to github 
Password for 'https://yarikoptic@github.com': 
publish(ok): . (dataset) [pushed to github: ['[new branch]', '[new branch]']]</code></pre>

   <ul>
	 <li>Anyone can now obtain not only my code but also the exact
	   version of the CIFAR dataset (if they want)</li>
	 <li>Information about data availability (git-annex branch) is published too</li>
	 <li>It is possible full hierarchies of datasets:
	   <br/>see <a href="http://datasets.datalad.org">http://datasets.datalad.org</a> with &gt; 480 TB of data, &gt; 1,000s of datasets in a hierarchy
	 </li>
   </ul>
  </section>

  <section>
	<h2>Export to FigShare</h2>
	<img style="" data-src="pics/datalad_process_tuned/export_preview.png">
  </section>

  <section>
  <h2>Export to FigShare (to share preprocessed data)</h2>
  <!-- IMG TODO -->
  <p>FigShare provides public publishing of datasets (no updates, like an "article")</p>
  <pre><code class="bash" style="max-height:none">cifar/ $ datalad export-to-figshare
[INFO   ] Uploading .../cifar/datalad_c2360714-4a98-11e9-a47c-8019340ce7f2.zip to figshare 
Article
Would you like to create a new article to upload to?
If not - we will list existing articles (choices: yes, no): yes
[INFO   ] Created a new (private) article 7886252 at https://figshare.com/account/articles/7886252. Please visit it, enter additional meta-data and make public
export_to_figshare(ok): &lt;Dataset path=.../cifar&gt;
   [Published archive https://ndownloader.figshare.com/files/14680097]
[INFO   ] Finished adding ...cifar/datalad_c2360714-4a98-11e9-a47c-8019340ce7f2.zip:
   Files processed: 10, removed: 10, +git: 7, +annex: 3

cifar/ $> datalad publish --to=github
[INFO   ] Publishing &lt;Dataset path=.../cifar&gt; to github 
publish(ok): . (dataset) [pushed to github: ['[up to date]', '47e2519..be2279b']]
  </code></pre>
  <ul>
	<li>Data now is available from a .zip on FigShare</li>
	<li>Anyone can now install the dataset from GitHub
	  <br/>and obtain raw or preprocessed data</li>
  </ul>
  </section>
</section>


<section>
  <section>
	<h2>Metadata</h2>
	<img style="" data-src="pics/datalad_process_tuned/metadata_preview.png">
  </section>

  <section>
    <h2>(Automated) Metadata logistics</h2>
    <ul>
        <li>Whole datasets and individual files can have metadata</li>
        <li>Metadata <strong>plurality:</strong> no need to decide on a single standard</li>
        <li><strong>JSON-LD</strong> format (for true semantic graphs, or simple dumps)</li>
        <li>Concept:
            <ul>
                <li>Metadata are <strong>automatically</strong> (and repeatedly) extracted from source content (EXIF from images, XMP from .pdf, ...)</li>
                <!--
				<li>Implementation of metadata extractors decides on content/structure</li>
                <li>Dataset authors/curators decide on extractor selection</li>
				-->
                <li>Metadata are managed by DataLad (optionally annexed), and can be separated from
                    a dataset and aggregated into super-datasets</li>
                <li>(Super)datasets can be <strong>queried</strong> for all available metadata of any content,
                    <strong>regardless of that content being locally available or not</strong></li>
            </ul>
        </li>
        <li>DataLad can serve as a transport layer for metadata</li>
		<li>Next generation metadata handling is coming in <a href="https://github.com/datalad/datalad-metalad">datalad-metalad</a></li>
    </ul>
    <note><a href="http://docs.datalad.org/en/latest/metadata.html#internal-metadata-representation">http://docs.datalad.org/en/latest/metadata.html#internal-metadata-representation</a></note>
  </section>

<!-- too much
<section>
<h2>Example JSON-LD metadata structure</h2>
<pre><code class="json" style="max-height:none">{
  "@context": {
    "@version": 1.1,
    "schema": "http://schema.org/",
    "name": "schema:name",
    "records": {
      "@id": "@graph",
      "@container": "@type"
    },
    "nidm": "http://nidm#",
    "niiri": "http://niiri#",
    "prov": "http://prov#",
    "atLocation": "http://prov#atLocation",
    "designMatrix": "nidm:designMatrix",
    "data": "nidm:designMatrix",
    "regressorNames": "nidm:regressorNames"
  },


  "name": "My NIDM graph",
  "records": {
    "designMatrix": {
      "@id": "niiri:0001",
      "name": "Some design matrix",
      "atLocation": "DesignMatrix.csv",
      "regressorNames": "[motor_left, motor_right]"
    },
    "data": {
      "@id": "niiri:0002",
      "name": "Some Data"
    }
  }
}
</code></pre>
<p><small>a true graph with defined terms, but processable without a graph representation</small></p>
</section>
-->

  <section>
    <h2>Metadata-based search for individual files</h2>
    <p style="margin-top:-1em">across datasets, without a DB (server)</p>
    <pre style="margin-top:-.5em"><code class="bash" style="max-height:none">$ datalad \
  -c datalad.search.index-egrep-documenttype=files \
  search \
    bids.subject.sex:female \
    bids.type:t1 \
    bids.subject.age:24
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000012/anat/sub-rid000012_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000012/anat/sub-rid000012_rec-ehalfhalf_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000024/anat/sub-rid000024_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000024/anat/sub-rid000024_rec-ehalfhalf_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000032/anat/sub-rid000032_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/labs/haxby/attention/sub-rid000032/anat/sub-rid000032_rec-ehalfhalf_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000001/sub-11/anat/sub-11_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000001/sub-15/anat/sub-15_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000002/sub-02/anat/sub-02_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000002/sub-05/anat/sub-05_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000005/sub-07/anat/sub-07_T1w.nii.gz (file)
search(ok): /home/yoh/datalad/openfmri/ds000006/sub-14/ses-retest/anat/sub-14_ses-retest_T1w.nii.gz (file)
...
    </code></pre>
  </section>


  <section>
    <h2>Metadata-based search for individual files (lots of metadata)</h2>
    <p style="margin-top:-1em">across datasets, without a DB (server)</p>
    <pre style="margin-top:-.5em"><code class="bash" style="max-height:none">$ datalad \
  -c datalad.search.index-egrep-documenttype=files \
  -f json_pp \
  search \
    bids.subject.sex:female \
    bids.type:t1 \
    bids.subject.age:24
{
  "dsid": "4842e188-7df5-11e6-8e6b-002590f97d84",
  "metadata": {
    "@context": {...},
    "bids": {...},
    "datalad_core": {
      "url": [
        "http://openneuro.s3.amazonaws.com/ds000008/ds000008_R1.1.0/...MZ92g",
        "http://openneuro.s3.amazonaws.com/ds000008/ds000008_R1.1.1/...UyanK",
        "http://openneuro.s3.amazonaws.com/ds000008/ds000008_R2.0.0/..._flBz"
      ]
    },
    "nifti1": {...},
  "parentds": "/home/yoh/datalad/openfmri/ds000008",
  "path": "/home/yoh/datalad/openfmri/ds000008/sub-15/anat/sub-15_T1w.nii.gz",
  "query_matched": {
    "bids.subject.age(years)": "24",
    "bids.subject.sex": "female",
    "bids.type": "T1"
  },
  "refcommit": "b18692ef1beefd88055bc0578b7567a8f4fdf8f9",
  "type": "file"
}
...
    </code></pre>
    <p style="margin-top:-.5em">alternative output formats: JSON stream, custom, ...</p>
  </section>
</section>

<section data-transition="zoom">
  <h2>DataLad API (recap and more)</h2>
  <img style="" data-src="pics/API-interdependencies.png">
</section>

<section>
  <section>
    <h2>Extend DataLad</h2>

	<p style="margin-top:1em;text-align:left">Besides coded-into DataLad, there are extensions:
    <ul>
        <li>Separate Python packages, anybody can develop their own</li>
        <li>Support for tailored solutions</li>
        <li>Can provide additional commands, procedures, metadata extractors,
            ...</li>
        <li>Available extensions
            <ul>
                <!-- <li><strong><a href="https://github.com/psychoinformatics-de/datalad-hirni">hirni</a></strong>: imaging raw data management/entry</li> -->
                <li><strong><a href="https://github.com/datalad/datalad-container">containers</a></strong>: support for containerized computational environments</li>
                <li><strong><a href="https://github.com/datalad/datalad-crawler">crawler</a></strong>: track web resources in automated data distributions</li>
                <li><strong><a href="https://github.com/datalad/datalad-neuroimaging">neuroimaging</a></strong>: neuroimaging research data and workflow</li>
                <!-- <li><strong><a href="https://github.com/datalad/datalad-webapp">webapp</a></strong>: REST API for querying/manipulating datasets</li> -->
                <li><strong><a href="https://github.com/datalad/datalad-fuse">fuse</a></strong>: use FSSPEC to provide sparse on-demand access to data and FUSE filesystem (on GNU/Linux)</li>
                <li><strong><a href="https://github.com/datalad/datalad-osf">osf</a></strong>: interface with the Open Science Framework</li>
                <li><strong><a href="https://github.com/datalad/datalad-ukbiobank">ukbiobank</a></strong>: work with the UKbiobank data</li>
				<li><strong><a href="https://github.com/datalad/datalad-xnat">xnat</a></strong>: alternative to crawler to track XNAT projects</li>

            </ul>
        </li>
    </ul>

    <note>
	  <a href="http://handbook.datalad.org/en/latest/extension_pkgs.html">http://handbook.datalad.org/en/latest/extension_pkgs.html</a> - canonical list in handbook
	  <a href="http://docs.datalad.org/en/latest/customization.html#extension-packages">http://docs.datalad.org/en/latest/customization.html#extension-packages</a> - devel docs<br/>
	  <a href="https://github.com/datalad/datalad-extensions/">https://github.com/datalad/datalad-extensions/</a> - health status<br/>
	</note>
  </section>
</section>

<section>
  <h2>Summary</h2>
  <img style="" data-src="pics/datalad_yoda.png">
  <note>
	See <a href="http://handbook.datalad.org/en/latest/code_from_chapters/ABCD.html">"An introduction to DataLad for the ABCD ReproNim course week 8b"</a> for more details and intro to <a href="https://github.com/myyoda/myyoda">YODA principles</a>.
  </note>
  <aside class="notes">
big picture slide, decentralized everything

no central service, no central storage

but capable of using any central service/storage

encyption, authorization
</aside>
</section>


<section>
  <h2>Acknowledgements</h2>
  <table>
  <tr style="vertical-align:middle">
      <td style="vertical-align:middle">
  <ul>
      <li>Michael Hanke</li>
      <li>Joey Hess (git-annex)</li>
      <li>Benjamin Poldrack</li>
      <li>Kyle Meyer</li>
      <li>Adina Wagner</li>
	  <li>John T. Wodder II</li>
      <li>40+ additional contributors</li>
  </ul>
      </td>
      <td style="vertical-align:middle">
  <img style="height:150px;margin-right:50px" data-src="pics/nsf.png" />
  <img style="height:150px;margin-right:50pxi;margin-left:50px" data-src="pics/binc.png" />
  <img style="height:150px;margin-left:50px" data-src="pics/bmbf.png" />
  </span>
  <br />
  <img style="height:80px;margin:20px" data-src="pics/nih.png" />
  <img style="height:80px;margin:20px" data-src="pics/erdf.png" />
  <img style="height:80px;margin:20px" data-src="pics/LSA-Logo.png" />
      </td>
  </tr>
  </table>
<p>
  Slides: <a href="https://github.com/datalad/talk-2022-abcd">https://github.com/datalad/talk-2020-abcd</a><br />
  Handbook: <a href="https://handbook.datalad.org">https://handbook.datalad.org</a><br />
  Website: <a href="http://datalad.org">http://datalad.org</a><br />
	Development: <a href="http://github.com/datalad">http://github.com/datalad</a><br />
	Announcements: <a href="http://twitter.com/datalad">http://twitter.com/datalad</a><br />
  Chat: <a href="https://matrix.to/#/#datalad:matrix.org">https://matrix.to/#/#datalad:matrix.org</a><br />
  Data (>480TBs): <a href="https://datasets.datalad.org">http://datasets.datalad.org</a></p>
</section>


<section>
  <section>
	<h2>Data provenance capture</h2>
	<img style="" data-src="pics/datalad_process_tuned/run_preview.png">
  </section>

  <section>
	<h2>Run anywhere: prepare a containerized environment</h2>
	<p>Not everyone has an environment I have!</p>
	<p>Prepare a Singularity container recipe for the environment:</p>
	<pre><code class="bash" style="max-height:none">cifar/environments $> datalad run -m "Creating Singularity file for preprocessing container" \
	bash -c 'docker run --rm kaczmarj/neurodocker:0.4.3 generate \
	singularity \
	--base neurodebian:stretch \
	-p apt \
	--miniconda pip_install="torch torchvision xarray netCDF4" \
	| sed -e "s, \(/var\)\?/tmp/\*,,g" \
	>| Singularity.preproc'
[INFO   ] == Command exit (modification check follows) =====
add(ok): environments/Singularity (file) [non-large file; adding content to git repository]
save(ok): .../cifar (dataset)
action summary:
add (ok: 1)
save (ok: 1)

$> datalad publish --to=github
[INFO   ] Publishing &lt;Dataset path=.../cifar&gt; to github
publish(ok): . (dataset) [pushed to github: ['19aa3a..47e251', '[up to date]']]</code></pre>
	<ul>
	  <li>Enabled GitHub repo on <a href="https://www.singularity-hub.org">https://www.singularity-hub.org</a></li>
	  <li>In a few minutes my Singularity container was created in the cloud</li>
	</ul>
  </section>

  <section>
	<h2>Run anywhere: add a containerized environment</h2>
	<img style="margin:-20px" data-src="pics/dataset_linkage_provenance.png">
	<p>Container image now could be added to the dataset</p>
	<pre><code class="bash" style="max-height:none">cifar/ $ datalad containers-add -i environments/preproc.simg \
	-u shub://yarikoptic/demo-cifar-preproc:preproc preproc
save(ok): .../cifar (dataset)
containers_add(ok): .../environments/preproc.simg (file)
action summary:
containers_add (ok: 1)
save (ok: 1)

cifar/ $ cat .datalad/config
...
[datalad "containers.preproc"]
updateurl = shub://yarikoptic/demo-cifar-preproc:preproc
image = environments/preproc.simg
cmdexec = singularity exec {img} {cmd}
	</code></pre>
	<ul>
	  <li>Singularity container is just a file, now annexed and available from the cloud</li>
	</ul>
  </section>

  <section data-background="pics/dataset_linkage_provenance.png">
	<h2>"Complete" provenance capture</h2>
	<p>We are ready to do the run in a container and publish update</p>
	<pre><code class="bash" style="max-height:none">cifar/ $ datalad containers-run -m "My reproducible preprocessing" -n preproc \
  --input data/rawdata/cifar-10-batches-py \
  python ./code/preprocessing.py data/rawdata data/preproc2 100
[INFO   ] Making sure inputs are available (this may take some time)
[INFO   ] == Command start (output follows) =====
Creating training dataset: batch 500/500
Creating test dataset: batch 100/100
[INFO   ] == Command exit (modification check follows) =====
add(ok): data/preproc2/test-100.h5 (file)
add(ok): data/preproc2/train-100.h5 (file)
save(ok): .../cifar (dataset)
action summary:
  add (ok: 2)
  get (notneeded: 3)
  save (ok: 1)

cifar/ $ git tag run-preproc2

cifar/ $ datalad publish --to=github
[INFO   ] Publishing &lt;Dataset path=.../cifar&gt; to github 
publish(ok): . (dataset) [pushed to github: ['d4afb4e..ee18230', 'be2279b..8e48fab']]

$ git push github run-preproc1 run-preproc2
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/yarikoptic/demo-cifar-preproc.git
 * [new tag]   run-preproc1 -> run-preproc1
 * [new tag]   run-preproc2 -> run-preproc2</code></pre>
  </section>

  <section>
	<h2>Apparently environment matters!?</h2>

	<pre><code class="bash" style="max-height:none">cifar/ $ h5diff -c data/preproc{1,2}/train-100.h5
attribute: &lt;_NCProperties of &lt;/&gt;&gt; and &lt;_NCProperties of &lt;/&gt;&gt;
20 differences found
Not comparable: &lt;/dim_0&gt; or &lt;/dim_0&gt; is an empty dataset
Not comparable: &lt;/dim_1&gt; or &lt;/dim_1&gt; is an empty dataset
Not comparable: &lt;/dim_2&gt; or &lt;/dim_2&gt; is an empty dataset
Not comparable: &lt;/dim_3&gt; or &lt;/dim_3&gt; is an empty dataset
Not comparable: &lt;/dim_4&gt; or &lt;/dim_4&gt; is an empty dataset</code></pre>
  <p>Homework:</p>
  <ul>
	<li>Install datalad, datalad-containers, and singularity</li>
	<li><pre><code>datalad install -r https://github.com/yarikoptic/demo-cifar-preproc</code></pre></li>
	<li><pre><code>datalad rerun run-preproc2</code></pre> should reproduce data/preproc2 (no new commit)</li>
	<li><pre><code>datalad rerun run-preproc1</code></pre> might reproduces data/preproc1 (new commit?)</li>
  </ul>
  </section>
</section>


</div> <!-- /.slides -->
</div> <!-- /.reveal -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
  // Full list of configuration options available at:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
    // The "normal" size of the presentation, aspect ratio will be preserved
    // when the presentation is scaled to fit different resolutions. Can be
    // specified using percentage units.
    width: 1280,
    height: 960,

    // Factor of the display size that should remain empty around the content
    margin: 0.1,

    // Bounds for smallest/largest possible scale to apply to content
    minScale: 0.2,
    maxScale: 1.0,

    controls: true,
    progress: true,
    history: true,
      center: false,

    transition: 'none', // none/fade/slide/convex/concave/zoom

    // Optional reveal.js plugins
    dependencies: [
      { src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'reveal.js/plugin/notes/notes.js', async: true }
    ]
  });
</script>
</body>
</html>
